{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                     # Llibreria matemÃƒ tica\n",
    "import matplotlib.pyplot as plt        # Per mostrar plots\n",
    "import sklearn                         # Llibreia de DM\n",
    "import sklearn.datasets as ds            # Per carregar mÃƒÂ©s facilment el dataset digits\n",
    "import sklearn.model_selection as cv    # Pel Cross-validation\n",
    "import sklearn.neighbors as nb           # Per fer servir el knn\n",
    "%matplotlib inline\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    # Numeric and matrix computation\n",
    "import pandas as pd   # Optional: good package for manipulating data \n",
    "import sklearn as sk  # Package with learning algorithms implemented\n",
    "\n",
    "# Loading the dataset.\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\"\n",
    "data = pd.read_csv(\"datapreprocessed.csv\", encoding='latin1')\n",
    "# data = data.sample(10000)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_categoric_column_with_binary_values(column_name):\n",
    "    global data\n",
    "    print(column_name)\n",
    "    print(data[column_name].unique())\n",
    "    data = pd.concat([\n",
    "            data.drop(column_name, axis=1),\n",
    "            pd.get_dummies(data[column_name], prefix=column_name, sparse=True)\n",
    "        ], axis=1)\n",
    "\n",
    "expand_categoric_column_with_binary_values('created')\n",
    "expand_categoric_column_with_binary_values('tweet_created')\n",
    "expand_categoric_column_with_binary_values('link_color')\n",
    "expand_categoric_column_with_binary_values('sidebar_color')\n",
    "expand_categoric_column_with_binary_values('tweet_location')\n",
    "expand_categoric_column_with_binary_values('user_timezone')\n",
    "\n",
    "data.head()\n",
    "\n",
    "def boolean_to_binary(column_name):\n",
    "    global data\n",
    "    data[column_name] = data[column_name].apply(lambda boolean: int(boolean))\n",
    "\n",
    "boolean_to_binary('tweet_coord')\n",
    "\n",
    "data.tweet_coord.sum()\n",
    "\n",
    "# All values must be numeric, label included\n",
    "def genderToNumeric(gender) :\n",
    "    if gender == 'male' :\n",
    "        return 0\n",
    "    elif gender == 'female' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 2\n",
    "\n",
    "\n",
    "labels = data.gender.apply(lambda g: genderToNumeric(g))\n",
    "datadt = data.drop('gender', axis=1)\n",
    "\n",
    "print(data.shape)\n",
    "datadt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation: split data into training and test sets (test 30% of data)\n",
    "(X_train, X_test,  y_train, y_test) = cv.train_test_split(datadt, labels, test_size=.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = StandardScaler().fit(X_train)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)).fit(X_train)\n",
    "\n",
    "# Apply the normalization trained in training data in both training and test sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM\n",
    "\n",
    "For C param 100 is chosed due to was executed with different values manually and it was the parameter with the best performance.\n",
    "\n",
    "In this case, is better search the best params using the GridSearch method, but the cost is high and is needed a powerful computer to calculate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Without K-Cross-Validation\n",
    "knc = SVC(kernel='linear', C=100)\n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "    \n",
    "print(\"Confusion matrix on last test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold-Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.svm import LinearSVC\n",
    "# import sklearn.cross_validation as cv\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# kf = cv.KFold(len(datadt),n_folds=3)\n",
    "# for train_index, test_index in kf :\n",
    "#     X_train, X_test = pd.core.frame.DataFrame(datadt, index = train_index), pd.core.frame.DataFrame(datadt ,index = test_index)\n",
    "#     y_train, y_test = pd.core.frame.DataFrame(labels, index = train_index), pd.core.frame.DataFrame(labels ,index = test_index)\n",
    "    \n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "    \n",
    "#     knc = SVC(kernel='linear', C=100)\n",
    "#     knc.fit(X_train, y_train)\n",
    "#     pred=knc.predict(X_test)\n",
    "    \n",
    "#     sum_accuracy += sklearn.metrics.accuracy_score(y_test, pred)\n",
    "    \n",
    "# print(\"Confusion matrix on last test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "# print()\n",
    "# print(f'Accuracy on test set: {sum_accuracy/kf.n_folds}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial kernels\n",
    "\n",
    "The C parameter is chosed manually for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "knc = SVC(kernel='poly',degree = 2, C=10) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold-Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# import sklearn.cross_validation as cv\n",
    "\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# kf = cv.KFold(len(datadt),n_folds=3)\n",
    "# for train_index, test_index in kf :\n",
    "#     X_train, X_test = pd.core.frame.DataFrame(datadt, index = train_index), pd.core.frame.DataFrame(datadt ,index = test_index)\n",
    "#     y_train, y_test = pd.core.frame.DataFrame(labels, index = train_index), pd.core.frame.DataFrame(labels ,index = test_index)\n",
    "    \n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "    \n",
    "#     knc = SVC(kernel='poly',degree = 2, C=10) \n",
    "#     knc.fit(X_train, y_train)\n",
    "#     pred=knc.predict(X_test)\n",
    "    \n",
    "# print(\"Confusion matrix on last test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "# print()\n",
    "# print(f'Accuracy on test set: {sum_accuracy/kf.n_folds}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "knc = SVC(kernel='poly',degree = 3, C=100) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold-Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# import sklearn.cross_validation as cv\n",
    "\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# kf = cv.KFold(len(datadt),n_folds=3)\n",
    "# for train_index, test_index in kf :\n",
    "#     X_train, X_test = pd.core.frame.DataFrame(datadt, index = train_index), pd.core.frame.DataFrame(datadt ,index = test_index)\n",
    "#     y_train, y_test = pd.core.frame.DataFrame(labels, index = train_index), pd.core.frame.DataFrame(labels ,index = test_index)\n",
    "    \n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "    \n",
    "#     knc = SVC(kernel='poly',degree = 3, C=100) \n",
    "#     knc.fit(X_train, y_train)\n",
    "#     pred=knc.predict(X_test)\n",
    "    \n",
    "# print(\"Confusion matrix on last test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "# print()\n",
    "# print(f'Accuracy on test set: {sum_accuracy/kf.n_folds}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "knc = SVC(C=180, gamma=0.1) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold-Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# import sklearn.cross_validation as cv\n",
    "\n",
    "\n",
    "# sum_accuracy = 0\n",
    "# kf = cv.KFold(len(datadt),n_folds=3)\n",
    "# for train_index, test_index in kf :\n",
    "#     X_train, X_test = pd.core.frame.DataFrame(datadt, index = train_index), pd.core.frame.DataFrame(datadt ,index = test_index)\n",
    "#     y_train, y_test = pd.core.frame.DataFrame(labels, index = train_index), pd.core.frame.DataFrame(labels ,index = test_index)\n",
    "    \n",
    "#     X_train = scaler.transform(X_train)\n",
    "#     X_test = scaler.transform(X_test)\n",
    "    \n",
    "#     knc = SVC(C=180, gamma=0.1) \n",
    "#     knc.fit(X_train, y_train)\n",
    "#     pred=knc.predict(X_test)\n",
    "    \n",
    "# print(\"Confusion matrix on last test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "# print()\n",
    "# print(f'Accuracy on test set: {sum_accuracy/kf.n_folds}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
