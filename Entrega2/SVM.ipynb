{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                     # Llibreria matemÃƒ tica\n",
    "import matplotlib.pyplot as plt        # Per mostrar plots\n",
    "import sklearn                         # Llibreia de DM\n",
    "import sklearn.datasets as ds            # Per carregar mÃƒÂ©s facilment el dataset digits\n",
    "import sklearn.model_selection as cv    # Pel Cross-validation\n",
    "import sklearn.neighbors as nb           # Per fer servir el knn\n",
    "%matplotlib inline              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>created</th>\n",
       "      <th>description_length</th>\n",
       "      <th>fav_number</th>\n",
       "      <th>link_color</th>\n",
       "      <th>name_length</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>sidebar_color</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>early_morning</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>cyan</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>109</td>\n",
       "      <td>False</td>\n",
       "      <td>110964</td>\n",
       "      <td>midday</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>midday</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>gray</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>139</td>\n",
       "      <td>False</td>\n",
       "      <td>7471</td>\n",
       "      <td>midday</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>morning</td>\n",
       "      <td>35</td>\n",
       "      <td>7696</td>\n",
       "      <td>gray</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>white</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>5617</td>\n",
       "      <td>midday</td>\n",
       "      <td>India</td>\n",
       "      <td>Belgrade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>evening</td>\n",
       "      <td>146</td>\n",
       "      <td>202</td>\n",
       "      <td>gray</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>white</td>\n",
       "      <td>138</td>\n",
       "      <td>False</td>\n",
       "      <td>1693</td>\n",
       "      <td>midday</td>\n",
       "      <td>United States</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>midday</td>\n",
       "      <td>160</td>\n",
       "      <td>37318</td>\n",
       "      <td>lightblue</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>black</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>31462</td>\n",
       "      <td>midday</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender        created  description_length  fav_number link_color  \\\n",
       "0    male  early_morning                  21           0       cyan   \n",
       "1    male         midday                  62          68       gray   \n",
       "2    male        morning                  35        7696       gray   \n",
       "3    male        evening                 146         202       gray   \n",
       "4  female         midday                 160       37318  lightblue   \n",
       "\n",
       "   name_length  retweet_count sidebar_color  text_length  tweet_coord  \\\n",
       "0            7              0         white          109        False   \n",
       "1           11              0         white          139        False   \n",
       "2           14              1         white           80        False   \n",
       "3           11              0         white          138        False   \n",
       "4           12              0         black           95        False   \n",
       "\n",
       "   tweet_count tweet_created tweet_location               user_timezone  \n",
       "0       110964        midday        Unknown                     Chennai  \n",
       "1         7471        midday        Unknown  Eastern Time (US & Canada)  \n",
       "2         5617        midday          India                    Belgrade  \n",
       "3         1693        midday  United States  Pacific Time (US & Canada)  \n",
       "4        31462        midday        Unknown                     Unknown  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np    # Numeric and matrix computation\n",
    "import pandas as pd   # Optional: good package for manipulating data \n",
    "import sklearn as sk  # Package with learning algorithms implemented\n",
    "\n",
    "# Loading the dataset.\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\"\n",
    "data = pd.read_csv(\"datapreprocessed.csv\", encoding='latin1')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created\n",
      "['early_morning' 'midday' 'morning' 'evening' 'afternoon']\n",
      "tweet_created\n",
      "['midday']\n",
      "link_color\n",
      "['cyan' 'gray' 'lightblue' 'lightred' 'blue' 'black' 'violet' 'red'\n",
      " 'orange' 'brown' 'green' 'lightgreen' 'white' 'yellow']\n",
      "sidebar_color\n",
      "['white' 'black' 'lightblue' 'orange' 'lightgreen' 'gray' 'lightred' 'cyan'\n",
      " 'red' 'brown' 'blue' 'yellow' 'violet' 'green']\n",
      "tweet_location\n",
      "['Unknown' 'India' 'United States' 'United Kingdom' 'Canada' 'Haiti'\n",
      " 'Saudi Arabia' 'Venezuela' 'Italy' 'Malaysia' 'Ireland' 'Poland' 'Spain'\n",
      " 'Belgium' 'Nigeria' 'Portugal' 'South Africa' 'New Zealand' 'France'\n",
      " 'Lebanon' 'Dominican Republic' 'Germany' 'Australia' 'Czechia' 'Croatia'\n",
      " 'Indonesia' 'Swaziland' 'Paraguay' 'Mexico' 'Ecuador' 'South Korea'\n",
      " 'Turkey' 'Syria' 'Greenland' 'Botswana' 'Brazil' 'Tunisia' 'Colombia'\n",
      " 'Greece' 'Trinidad and Tobago' 'Bangladesh' 'Somalia' 'Netherlands'\n",
      " 'Sweden' 'Hong Kong' 'Argentina' 'Japan' 'Egypt' 'Israel' 'Bolivia'\n",
      " 'Bosnia & Herzegovina' 'Sri Lanka' 'North Africa' 'United Arab Emirates'\n",
      " 'Kenya' 'Ghana' 'Pakistan' 'Namibia' 'Singapore' 'Finland' 'Norway'\n",
      " 'Philippines' 'Sudan' 'Switzerland' 'Zimbabwe' 'North Korea' 'Uganda'\n",
      " 'Cayman Islands' 'Kuwait' 'Zambia' 'Bahamas' 'Costa Rica' 'Maldives'\n",
      " 'Mauritius' 'Denmark' 'Rwanda' 'Dominica' 'Slovakia' 'Austria' 'Romania'\n",
      " 'Jersey' 'Jamaica' 'Vietnam' 'Thailand' 'Taiwan' 'Hungary' 'China'\n",
      " 'Iceland' 'Chile' 'Aruba' 'Cuba' 'Puerto Rico' 'Burundi' 'Russia'\n",
      " 'Honduras' 'Lesotho' 'Guatemala' 'Malawi' 'Guernsey' 'Jordan' 'Peru'\n",
      " 'Belize' 'Lithuania' 'Bahrain' 'Vatican City' 'Isle of Man' 'Uzbekistan'\n",
      " 'Morocco' 'Gibraltar' 'Tanzania' 'Uruguay' 'Panama' 'Oman' 'Algeria'\n",
      " 'Antigua and Barbuda' 'Svalbard and Jan Mayen' 'Afghanistan' 'Qatar'\n",
      " 'Iran' 'Cameroon' 'Liechtenstein' 'Latvia' 'Cyprus' 'Serbia' 'Ukraine'\n",
      " \"Côte d'Ivoire\" 'Guyana' 'Nicaragua' 'Saint Lucia' 'Albania' 'Angola'\n",
      " 'Grenada' 'El Salvador' 'Iraq' 'Mongolia' 'Guam']\n",
      "user_timezone\n",
      "['Chennai' 'Eastern Time (US & Canada)' 'Belgrade'\n",
      " 'Pacific Time (US & Canada)' 'Unknown' 'Central Time (US & Canada)'\n",
      " 'Amsterdam' 'Atlantic Time (Canada)' 'Arizona' 'London'\n",
      " 'Mountain Time (US & Canada)' 'Hawaii' 'Caracas' 'Krasnoyarsk'\n",
      " 'Casablanca' 'Tijuana' 'Abu Dhabi' 'America/Los_Angeles' 'Baghdad'\n",
      " 'Edinburgh' 'Tokyo' 'Riyadh' 'Hong Kong' 'Seoul' 'Athens' 'Dublin'\n",
      " 'Madrid' 'Quito' 'Brussels' 'Sydney' 'Berlin' 'Pretoria' 'Wellington'\n",
      " 'Beijing' 'Greenland' 'Urumqi' 'Alaska' 'Bangkok' 'Skopje' 'Melbourne'\n",
      " 'Monterrey' 'Jakarta' 'Rome' 'Europe/Athens' 'Paris' 'Cape Verde Is.'\n",
      " 'America/New_York' 'Yerevan' 'Nairobi' \"Nuku'alofa\" 'Mid-Atlantic'\n",
      " 'Saskatchewan' 'UTC' 'Bogota' 'Prague' 'Auckland' 'Bucharest' 'Brasilia'\n",
      " 'Irkutsk' 'Midway Island' 'America/Chicago' 'West Central Africa' 'Vienna'\n",
      " 'Ljubljana' 'Brisbane' 'Buenos Aires' 'Stockholm' 'Samoa' 'Santiago'\n",
      " 'Jerusalem' 'Mexico City' 'Newfoundland' 'International Date Line West'\n",
      " 'Helsinki' 'Volgograd' 'La Paz' 'Sofia' 'Sri Jayawardenepura' 'Zagreb'\n",
      " 'Kyiv' 'Lisbon' 'Karachi' 'Chihuahua' 'Mumbai' 'Cairo' 'Bern' 'New Delhi'\n",
      " 'Azores' 'Adelaide' 'Singapore' 'Tehran' 'Dhaka' 'Kuala Lumpur' 'Hanoi'\n",
      " 'America/Toronto' 'Almaty' 'Muscat' 'Asia/Karachi' 'Budapest'\n",
      " 'Solomon Is.' 'Indiana (East)' 'Bratislava' 'Africa/Cairo' 'Perth'\n",
      " 'Istanbul' 'Baku' 'America/Vancouver' 'New Caledonia' 'Europe/London'\n",
      " 'Kuwait' 'Minsk' 'Africa/Lagos' 'Mazatlan' 'Harare' 'Islamabad'\n",
      " 'Ekaterinburg' 'Tallinn' 'Copenhagen' 'Moscow' 'Warsaw' 'Georgetown'\n",
      " 'Yakutsk' 'Monrovia' 'EDT' 'GMT+3' 'Magadan' 'Tashkent' 'Central America'\n",
      " 'Fiji' 'Kabul' 'Canberra' 'Kolkata' 'Darwin' 'Ulaan Bataar'\n",
      " 'America/Boise' 'PDT' 'Osaka' 'CST' 'Europe/Paris' 'Riga' 'Vilnius' 'Lima'\n",
      " 'Guam' 'Hobart' 'BST' 'Africa/Nairobi' 'America/Detroit' 'CDT'\n",
      " 'Europe/Sarajevo' 'PST' 'Taipei' 'IST' 'Novosibirsk'\n",
      " 'America/Argentina/Buenos_Aires']\n",
      "(18836, 332)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description_length</th>\n",
       "      <th>fav_number</th>\n",
       "      <th>name_length</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>created_afternoon</th>\n",
       "      <th>created_early_morning</th>\n",
       "      <th>created_evening</th>\n",
       "      <th>...</th>\n",
       "      <th>user_timezone_Urumqi</th>\n",
       "      <th>user_timezone_Vienna</th>\n",
       "      <th>user_timezone_Vilnius</th>\n",
       "      <th>user_timezone_Volgograd</th>\n",
       "      <th>user_timezone_Warsaw</th>\n",
       "      <th>user_timezone_Wellington</th>\n",
       "      <th>user_timezone_West Central Africa</th>\n",
       "      <th>user_timezone_Yakutsk</th>\n",
       "      <th>user_timezone_Yerevan</th>\n",
       "      <th>user_timezone_Zagreb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>110964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>7471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>7696</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>5617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>146</td>\n",
       "      <td>202</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>1693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>37318</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>31462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   description_length  fav_number  name_length  retweet_count  text_length  \\\n",
       "0                  21           0            7              0          109   \n",
       "1                  62          68           11              0          139   \n",
       "2                  35        7696           14              1           80   \n",
       "3                 146         202           11              0          138   \n",
       "4                 160       37318           12              0           95   \n",
       "\n",
       "   tweet_coord  tweet_count  created_afternoon  created_early_morning  \\\n",
       "0            0       110964                  0                      1   \n",
       "1            0         7471                  0                      0   \n",
       "2            0         5617                  0                      0   \n",
       "3            0         1693                  0                      0   \n",
       "4            0        31462                  0                      0   \n",
       "\n",
       "   created_evening          ...           user_timezone_Urumqi  \\\n",
       "0                0          ...                              0   \n",
       "1                0          ...                              0   \n",
       "2                0          ...                              0   \n",
       "3                1          ...                              0   \n",
       "4                0          ...                              0   \n",
       "\n",
       "   user_timezone_Vienna  user_timezone_Vilnius  user_timezone_Volgograd  \\\n",
       "0                     0                      0                        0   \n",
       "1                     0                      0                        0   \n",
       "2                     0                      0                        0   \n",
       "3                     0                      0                        0   \n",
       "4                     0                      0                        0   \n",
       "\n",
       "   user_timezone_Warsaw  user_timezone_Wellington  \\\n",
       "0                     0                         0   \n",
       "1                     0                         0   \n",
       "2                     0                         0   \n",
       "3                     0                         0   \n",
       "4                     0                         0   \n",
       "\n",
       "   user_timezone_West Central Africa  user_timezone_Yakutsk  \\\n",
       "0                                  0                      0   \n",
       "1                                  0                      0   \n",
       "2                                  0                      0   \n",
       "3                                  0                      0   \n",
       "4                                  0                      0   \n",
       "\n",
       "   user_timezone_Yerevan  user_timezone_Zagreb  \n",
       "0                      0                     0  \n",
       "1                      0                     0  \n",
       "2                      0                     0  \n",
       "3                      0                     0  \n",
       "4                      0                     0  \n",
       "\n",
       "[5 rows x 331 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def expand_categoric_column_with_binary_values(column_name):\n",
    "    global data\n",
    "    print(column_name)\n",
    "    print(data[column_name].unique())\n",
    "    data = pd.concat([\n",
    "            data.drop(column_name, axis=1),\n",
    "            pd.get_dummies(data[column_name], prefix=column_name, sparse=True)\n",
    "        ], axis=1)\n",
    "\n",
    "expand_categoric_column_with_binary_values('created')\n",
    "expand_categoric_column_with_binary_values('tweet_created')\n",
    "expand_categoric_column_with_binary_values('link_color')\n",
    "expand_categoric_column_with_binary_values('sidebar_color')\n",
    "expand_categoric_column_with_binary_values('tweet_location')\n",
    "expand_categoric_column_with_binary_values('user_timezone')\n",
    "\n",
    "data.head()\n",
    "\n",
    "def boolean_to_binary(column_name):\n",
    "    global data\n",
    "    data[column_name] = data[column_name].apply(lambda boolean: int(boolean))\n",
    "\n",
    "boolean_to_binary('tweet_coord')\n",
    "\n",
    "data.tweet_coord.sum()\n",
    "\n",
    "# All values must be numeric, label included\n",
    "def genderToNumeric(gender) :\n",
    "    if gender == 'male' :\n",
    "        return 0\n",
    "    elif gender == 'female' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 2\n",
    "\n",
    "\n",
    "labels = data.gender.apply(lambda g: genderToNumeric(g))\n",
    "datadt = data.drop('gender', axis=1)\n",
    "\n",
    "print(data.shape)\n",
    "datadt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation: split data into training and test sets (test 30% of data)\n",
    "(X_train, X_test,  y_train, y_test) = cv.train_test_split(datadt, labels, test_size=.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the stratification according to labels *y* that we demand in the spliting of data. The ionosphere dataset is small and with strarification we ensure we obtain the same proportion of examples of each class in training and test sets.\n",
    "\n",
    "**Remember**. Data should be numerical and normalized or standarized before using an SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization is not strictily necessary in our dataset because almost all columns are in range -1..1 (except columns 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>description_length</th>\n",
       "      <th>fav_number</th>\n",
       "      <th>name_length</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text_length</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>created_afternoon</th>\n",
       "      <th>created_early_morning</th>\n",
       "      <th>...</th>\n",
       "      <th>user_timezone_Urumqi</th>\n",
       "      <th>user_timezone_Vienna</th>\n",
       "      <th>user_timezone_Vilnius</th>\n",
       "      <th>user_timezone_Volgograd</th>\n",
       "      <th>user_timezone_Warsaw</th>\n",
       "      <th>user_timezone_Wellington</th>\n",
       "      <th>user_timezone_West Central Africa</th>\n",
       "      <th>user_timezone_Yakutsk</th>\n",
       "      <th>user_timezone_Yerevan</th>\n",
       "      <th>user_timezone_Zagreb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>110964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>62</td>\n",
       "      <td>68</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>7471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>7696</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>5617</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>146</td>\n",
       "      <td>202</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>1693</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>160</td>\n",
       "      <td>37318</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>31462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  description_length  fav_number  name_length  retweet_count  \\\n",
       "0    male                  21           0            7              0   \n",
       "1    male                  62          68           11              0   \n",
       "2    male                  35        7696           14              1   \n",
       "3    male                 146         202           11              0   \n",
       "4  female                 160       37318           12              0   \n",
       "\n",
       "   text_length  tweet_coord  tweet_count  created_afternoon  \\\n",
       "0          109            0       110964                  0   \n",
       "1          139            0         7471                  0   \n",
       "2           80            0         5617                  0   \n",
       "3          138            0         1693                  0   \n",
       "4           95            0        31462                  0   \n",
       "\n",
       "   created_early_morning          ...           user_timezone_Urumqi  \\\n",
       "0                      1          ...                              0   \n",
       "1                      0          ...                              0   \n",
       "2                      0          ...                              0   \n",
       "3                      0          ...                              0   \n",
       "4                      0          ...                              0   \n",
       "\n",
       "   user_timezone_Vienna  user_timezone_Vilnius  user_timezone_Volgograd  \\\n",
       "0                     0                      0                        0   \n",
       "1                     0                      0                        0   \n",
       "2                     0                      0                        0   \n",
       "3                     0                      0                        0   \n",
       "4                     0                      0                        0   \n",
       "\n",
       "   user_timezone_Warsaw  user_timezone_Wellington  \\\n",
       "0                     0                         0   \n",
       "1                     0                         0   \n",
       "2                     0                         0   \n",
       "3                     0                         0   \n",
       "4                     0                         0   \n",
       "\n",
       "   user_timezone_West Central Africa  user_timezone_Yakutsk  \\\n",
       "0                                  0                      0   \n",
       "1                                  0                      0   \n",
       "2                                  0                      0   \n",
       "3                                  0                      0   \n",
       "4                                  0                      0   \n",
       "\n",
       "   user_timezone_Yerevan  user_timezone_Zagreb  \n",
       "0                      0                     0  \n",
       "1                      0                     0  \n",
       "2                      0                     0  \n",
       "3                      0                     0  \n",
       "4                      0                     0  \n",
       "\n",
       "[5 rows x 332 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, let's see how to do that properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = StandardScaler().fit(X_train)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)).fit(X_train)\n",
    "\n",
    "# Apply the normalization trained in training data in both training and test sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM\n",
    "\n",
    "Let's try an SVM with default parameters. Linear means that we are not using any kernel to move the data to a higher dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix on test set:\n",
      " [[ 708  556  551]\n",
      " [ 480  967  584]\n",
      " [ 444  347 1014]]\n",
      "\n",
      "Accuracy on test set:  0.475844983189\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#knc = LinearSVC() \n",
    "knc = SVC(kernel='linear')\n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad results. However, the linear SVM has parameter C that has to be adjusted. We will use *GridSearch* method to find the optimal value of C like we did in a previous notebook with the k value of the KNN algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of C values to test. We usualy test diverse orders of magnitude\n",
    "#Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "Cs = np.logspace(-3, 5, num=9, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "#grid_search = GridSearchCV(LinearSVC(), param_grid, cv=10)\n",
    "grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "# Let's plot the 10-fold cross.validation accuracy deppending on C\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "# Let's apply the best C parameter found to the test set\n",
    "parval=grid_search.best_params_\n",
    "#knc = LinearSVC(C=parval['C']) \n",
    "knc = SVC(C=parval['C'],kernel='linear')\n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nBest value of parameter C found: \",parval)\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this dataset, the best C for a linear SVM is 1 (that casually is also the default value for parameter C) so we don't obtain any improvement tuning the C parameter. However, in other datasets we could obtain a dramatic increase of accuracy. \n",
    "\n",
    "Let's see (just for fun) how the C parameter affects performance on training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plot_validation_curve(parameter_values, train_scores, validation_scores):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(parameter_values, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(parameter_values, validation_scores_mean - validation_scores_std,\n",
    "                     validation_scores_mean + validation_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(parameter_values, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(parameter_values, validation_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.ylim(validation_scores_mean.min() - .1, train_scores_mean.max() + .1)\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "\n",
    "training_scores, test_scores = validation_curve(SVC(kernel='linear'), X_train, y_train, param_name=\"C\", param_range=Cs,cv=10)\n",
    "plot_validation_curve(range(len(Cs)), training_scores, test_scores)\n",
    "plt.xticks(range(len(Cs)), Cs,rotation='vertical');\n",
    "plt.ylim([0.6, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that from value of C=1, increasing C results in better accuracy on the training set but worse performance on the test set. This is because being too demanding on the separation of data in the training dataset, we are overfitting to it and we decrease performance in the test set. A nice picture of typical overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial kernels\n",
    "\n",
    "We have seen that performance with a linear SVM is Ok but not competitive with Metamethods. However, it could happen that using kernels we could even improve accuracy. We'll try first ploynomial kernel with degree 2 with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knc = SVC(kernel='poly',degree =2) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better performance than the obtained with a linear SVM... It could even be increased because we didn't tune the C parameter for the polynomial kernel. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly',degree =2) , param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "parval=grid_search.best_params_\n",
    "knc = SVC(kernel='poly',degree =2,C=parval['C']) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nBest combination of parameters found: \",parval)\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result so far. Competitive with meta-methods. Now the best C value found is 100 and accuracy is a lot higher than with default parameters. It's always important when working with SVMs to find best parameters. \n",
    "\n",
    "For this C value we have a nice accuracy on the test set. Let's try what happens now with a polynomial kernel of degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knc = SVC(kernel='poly',degree =3) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very bad results! That's because, again, we didn't use the optimal value for the C parameter but the default one. Let's find the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly',degree =3) , param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "parval=grid_search.best_params_\n",
    "knc = SVC(kernel='poly',degree =3,C=parval['C']) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nBest combination of parameters found: \",parval)\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix shows only 1 more error than the confusion matrix obtained with the quadratic kernel. Given the low number of cases we have in the test set, we cannot conclude that polynomial kernel with degree 2 is better than with degree 3. But remember that when there are several classifiers with a similar performance, we should always choose the simpler one! So we will choose the quadratic polynomial kernel as best polynomial kernel, not because of performance only but because is the better combination of performance and simplicity.\n",
    "\n",
    "## RBF Kernel\n",
    "\n",
    "There's another possibility for the kernel: The RBF kernel. This is the default kernel in the implementation of SVMs in sklearn, so we don't need to explicitely say the kernel used. Let's try it with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knc = SVC() \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promising performance for default parameters. But we have to search for the best parameters. In this case we have two parameters to adjust: the C parameter and the gamma parameter. We will find the best combination using the *GridSearch* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Values we will test for each parameter. When observin results, consider the limits of the \n",
    "# values tested and increase them if necessary \n",
    "gammas = [0.000001,0.00001, 0.0001,0.001,0.01,0.1,1,10]\n",
    "Cs = np.logspace(-1, 6, num=8, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "parval=grid_search.best_params_\n",
    "\n",
    "# We'll show in a grid, the accuracy for each combination of parameters tester\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "scores = np.array(scores).reshape(len(param_grid['C']), len(param_grid['gamma']))\n",
    "\n",
    "plt.matshow(scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(param_grid['gamma'])), param_grid['gamma'],rotation='vertical')\n",
    "plt.yticks(np.arange(len(param_grid['C'])), param_grid['C'])\n",
    "plt.show()\n",
    "print(\"\\nBest combination of parameters found: \",parval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This picture show for each combination of parameters the accuracy obtained in a 10-fold cross-validation. Notice the relation between C and gamma. \n",
    "\n",
    "Let's see the performance of the best parameters found on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's apply the best combination of parameters found to the test set\n",
    "parval=grid_search.best_params_\n",
    "knc = SVC(C=parval['C'], gamma=parval['gamma']) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow. Best performance obtained so far using any method, even better than results obtained with meta-methods. \n",
    "\n",
    "**Observations about number and percentage of supports vectors:** \n",
    "It is know that percentage of supports of an SVM is a lower bound for the leave-one-out error. In general, an SVM with a lot of supports will be an overfitted SVM. A percentage of supports higher than 50% should be considered suspicious. If this happens, try to use other kernels. As a rule of thumb, a good SVM has a percentatge of supports vectors about 20-40% of the data (but that depends on a lot of things).\n",
    "\n",
    "In our case all SVM have a low number of supports. And notice that the machine with a higher performance is the one with a lower number of supports (24.9%). That's not a coincidence but something common in SVMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Performance of meta-methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf=ExtraTreesClassifier(n_estimators=200,random_state=1).fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf=AdaBoostClassifier(n_estimators=200,random_state=1).fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clf=BaggingClassifier(n_estimators=200,max_features=0.35,random_state=1).fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
