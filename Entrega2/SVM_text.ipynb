{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                     # Llibreria matemÃƒ tica\n",
    "import matplotlib.pyplot as plt        # Per mostrar plots\n",
    "import sklearn\n",
    "import sklearn.datasets as ds            # Per carregar mÃƒÂ©s facilment el dataset digits\n",
    "import sklearn.model_selection as cv    # Pel Cross-validation\n",
    "import sklearn.neighbors as nb           # Per fer servir el knn\n",
    "%matplotlib inline              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender:confidence</th>\n",
       "      <th>profile_yn</th>\n",
       "      <th>profile_yn:confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>evidence</th>\n",
       "      <th>great.</th>\n",
       "      <th>toe</th>\n",
       "      <th>favor</th>\n",
       "      <th>soccer</th>\n",
       "      <th>did.</th>\n",
       "      <th>wheel</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>rank</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>815719226</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:24</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>815719227</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:30</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>815719228</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:33</td>\n",
       "      <td>male</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>815719229</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/26/15 23:10</td>\n",
       "      <td>male</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>815719230</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>10/27/15 1:15</td>\n",
       "      <td>female</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   _unit_id  _golden _unit_state  _trusted_judgments  \\\n",
       "0           0  815719226    False   finalized                   3   \n",
       "1           1  815719227    False   finalized                   3   \n",
       "2           2  815719228    False   finalized                   3   \n",
       "3           3  815719229    False   finalized                   3   \n",
       "4           4  815719230    False   finalized                   3   \n",
       "\n",
       "  _last_judgment_at  gender  gender:confidence profile_yn  \\\n",
       "0    10/26/15 23:24    male             1.0000        yes   \n",
       "1    10/26/15 23:30    male             1.0000        yes   \n",
       "2    10/26/15 23:33    male             0.6625        yes   \n",
       "3    10/26/15 23:10    male             1.0000        yes   \n",
       "4     10/27/15 1:15  female             1.0000        yes   \n",
       "\n",
       "   profile_yn:confidence   ...    evidence great.  toe favor soccer did.  \\\n",
       "0                    1.0   ...           0      0    0     0      0    0   \n",
       "1                    1.0   ...           0      0    0     0      0    0   \n",
       "2                    1.0   ...           0      0    0     0      0    0   \n",
       "3                    1.0   ...           0      0    0     0      0    0   \n",
       "4                    1.0   ...           0      0    0     0      0    0   \n",
       "\n",
       "  wheel shoulder  rank expected  \n",
       "0     0        0     0        0  \n",
       "1     0        0     0        0  \n",
       "2     0        0     0        0  \n",
       "3     0        0     0        0  \n",
       "4     0        0     0        0  \n",
       "\n",
       "[5 rows x 2027 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np    # Numeric and matrix computation\n",
    "import pandas as pd   # Optional: good package for manipulating data \n",
    "import sklearn as sk  # Package with learning algorithms implemented\n",
    "\n",
    "# Loading the dataset.\n",
    "url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\"\n",
    "data = pd.read_csv(\"dataWithTextWordsPrep.csv\", encoding='latin1', low_memory=False)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18836, 2001)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>you</th>\n",
       "      <th>weather</th>\n",
       "      <th>get</th>\n",
       "      <th>my</th>\n",
       "      <th>from</th>\n",
       "      <th>me</th>\n",
       "      <th>with</th>\n",
       "      <th>that</th>\n",
       "      <th>update</th>\n",
       "      <th>...</th>\n",
       "      <th>evidence</th>\n",
       "      <th>great.</th>\n",
       "      <th>toe</th>\n",
       "      <th>favor</th>\n",
       "      <th>soccer</th>\n",
       "      <th>did.</th>\n",
       "      <th>wheel</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>rank</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  you  weather  get  my  from  me  with  that  update    ...     \\\n",
       "0    male    0        0    0   0     0   0     0     0       0    ...      \n",
       "1    male    0        0    0   1     0   0     1     0       0    ...      \n",
       "2    male    0        0    0   0     0   1     0     0       0    ...      \n",
       "3    male    1        0    0   0     0   0     0     0       0    ...      \n",
       "4  female    0        0    0   0     0   0     1     0       0    ...      \n",
       "\n",
       "   evidence  great.  toe  favor  soccer  did.  wheel  shoulder  rank  expected  \n",
       "0         0       0    0      0       0     0      0         0     0         0  \n",
       "1         0       0    0      0       0     0      0         0     0         0  \n",
       "2         0       0    0      0       0     0      0         0     0         0  \n",
       "3         0       0    0      0       0     0      0         0     0         0  \n",
       "4         0       0    0      0       0     0      0         0     0         0  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['Unnamed: 0', '_unit_id', '_golden', '_unit_state', '_trusted_judgments', '_last_judgment_at',\n",
    "               'gender:confidence', 'profile_yn', 'profile_yn:confidence', 'created', 'description',\n",
    "               'fav_number', 'gender_gold', 'link_color', 'name', 'profile_yn_gold', 'profileimage',\n",
    "               'sidebar_color', 'text', 'tweet_count', 'tweet_created', 'tweet_id', 'tweet_location',\n",
    "               'retweet_count', 'tweet_coord', 'user_timezone'], axis=1);\n",
    "data = data[data.gender.notnull()]\n",
    "data.head()\n",
    "\n",
    "def genderToNumeric(gender) :\n",
    "    if gender == 'male' :\n",
    "        return 0\n",
    "    elif gender == 'female' :\n",
    "        return 1\n",
    "    else :\n",
    "        return 2\n",
    "\n",
    "labels = data.gender.apply(lambda g: genderToNumeric(g))\n",
    "datadt = data.drop('gender', axis=1)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-validation: split data into training and test sets (test 30% of data)\n",
    "(X_train, X_test,  y_train, y_test) = cv.train_test_split(datadt, labels, test_size=.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the stratification according to labels *y* that we demand in the spliting of data. The ionosphere dataset is small and with strarification we ensure we obtain the same proportion of examples of each class in training and test sets.\n",
    "\n",
    "**Remember**. Data should be numerical and normalized or standarized before using an SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization is not strictily necessary in our dataset because almost all columns are in range -1..1 (except columns 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>you</th>\n",
       "      <th>weather</th>\n",
       "      <th>get</th>\n",
       "      <th>my</th>\n",
       "      <th>from</th>\n",
       "      <th>me</th>\n",
       "      <th>with</th>\n",
       "      <th>that</th>\n",
       "      <th>update</th>\n",
       "      <th>...</th>\n",
       "      <th>evidence</th>\n",
       "      <th>great.</th>\n",
       "      <th>toe</th>\n",
       "      <th>favor</th>\n",
       "      <th>soccer</th>\n",
       "      <th>did.</th>\n",
       "      <th>wheel</th>\n",
       "      <th>shoulder</th>\n",
       "      <th>rank</th>\n",
       "      <th>expected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  you  weather  get  my  from  me  with  that  update    ...     \\\n",
       "0    male    0        0    0   0     0   0     0     0       0    ...      \n",
       "1    male    0        0    0   1     0   0     1     0       0    ...      \n",
       "2    male    0        0    0   0     0   1     0     0       0    ...      \n",
       "3    male    1        0    0   0     0   0     0     0       0    ...      \n",
       "4  female    0        0    0   0     0   0     1     0       0    ...      \n",
       "\n",
       "   evidence  great.  toe  favor  soccer  did.  wheel  shoulder  rank  expected  \n",
       "0         0       0    0      0       0     0      0         0     0         0  \n",
       "1         0       0    0      0       0     0      0         0     0         0  \n",
       "2         0       0    0      0       0     0      0         0     0         0  \n",
       "3         0       0    0      0       0     0      0         0     0         0  \n",
       "4         0       0    0      0       0     0      0         0     0         0  \n",
       "\n",
       "[5 rows x 2001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, let's see how to do that properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#scaler = StandardScaler().fit(X_train)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1)).fit(X_train)\n",
    "\n",
    "# Apply the normalization trained in training data in both training and test sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM\n",
    "\n",
    "Let's try an SVM with default parameters. Linear means that we are not using any kernel to move the data to a higher dimensional space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 1\n",
      "Confusion matrix on test set:\n",
      " [[ 769  700  346]\n",
      " [ 706 1062  263]\n",
      " [ 510  383  912]]\n",
      "\n",
      "Accuracy on test set:  0.485400814015\n",
      "\n",
      "For C = 5\n",
      "Confusion matrix on test set:\n",
      " [[ 782  672  361]\n",
      " [ 721 1044  266]\n",
      " [ 498  390  917]]\n",
      "\n",
      "Accuracy on test set:  0.485400814015\n",
      "\n",
      "For C = 50\n",
      "Confusion matrix on test set:\n",
      " [[ 805  644  366]\n",
      " [ 724 1034  273]\n",
      " [ 491  378  936]]\n",
      "\n",
      "Accuracy on test set:  0.491063528579\n",
      "\n",
      "For C = 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "csArray = [1, 5, 50, 100]\n",
    "for cElem in csArray :\n",
    "    print (f'For C = {cElem}')\n",
    "    knc = SVC(kernel='linear', C=cElem)\n",
    "    knc.fit(X_train, y_train)\n",
    "    pred=knc.predict(X_test)\n",
    "    print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "    print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad results. However, the linear SVM has parameter C that has to be adjusted. We will use *GridSearch* method to find the optimal value of C like we did in a previous notebook with the k value of the KNN algorithm.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of C values to test. We usualy test diverse orders of magnitude\n",
    "#Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "Cs = np.logspace(-3, 5, num=9, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "#grid_search = GridSearchCV(LinearSVC(), param_grid, cv=10)\n",
    "grid_search = GridSearchCV(SVC(kernel='linear'), param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "# Let's plot the 10-fold cross.validation accuracy deppending on C\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "# Let's apply the best C parameter found to the test set\n",
    "parval=grid_search.best_params_\n",
    "#knc = LinearSVC(C=parval['C']) \n",
    "knc = SVC(C=parval['C'],kernel='linear')\n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nBest value of parameter C found: \",parval)\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this dataset, the best C for a linear SVM is 1 (that casually is also the default value for parameter C) so we don't obtain any improvement tuning the C parameter. However, in other datasets we could obtain a dramatic increase of accuracy. \n",
    "\n",
    "Let's see (just for fun) how the C parameter affects performance on training and test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plot_validation_curve(parameter_values, train_scores, validation_scores):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = np.mean(validation_scores, axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "\n",
    "    plt.fill_between(parameter_values, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(parameter_values, validation_scores_mean - validation_scores_std,\n",
    "                     validation_scores_mean + validation_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(parameter_values, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(parameter_values, validation_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "    plt.ylim(validation_scores_mean.min() - .1, train_scores_mean.max() + .1)\n",
    "    plt.legend(loc=4)\n",
    "\n",
    "\n",
    "training_scores, test_scores = validation_curve(SVC(kernel='linear'), X_train, y_train, param_name=\"C\", param_range=Cs,cv=10)\n",
    "plot_validation_curve(range(len(Cs)), training_scores, test_scores)\n",
    "plt.xticks(range(len(Cs)), Cs,rotation='vertical');\n",
    "plt.ylim([0.6, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that from value of C=1, increasing C results in better accuracy on the training set but worse performance on the test set. This is because being too demanding on the separation of data in the training dataset, we are overfitting to it and we decrease performance in the test set. A nice picture of typical overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial kernels\n",
    "\n",
    "We have seen that performance with a linear SVM is Ok but not competitive with Metamethods. However, it could happen that using kernels we could even improve accuracy. We'll try first ploynomial kernel with degree 2 with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 1\n",
      "Confusion matrix on test set:\n",
      " [[  13 1802    0]\n",
      " [   2 2026    3]\n",
      " [  11 1448  346]]\n",
      "\n",
      "Accuracy on test set:  0.422049194833\n",
      "\n",
      "For C = 5\n",
      "Confusion matrix on test set:\n",
      " [[1086  636   93]\n",
      " [ 889 1059   83]\n",
      " [ 818  353  634]]\n",
      "\n",
      "Accuracy on test set:  0.491771367899\n",
      "\n",
      "For C = 50\n",
      "Confusion matrix on test set:\n",
      " [[ 846  693  276]\n",
      " [ 700 1115  216]\n",
      " [ 485  398  922]]\n",
      "\n",
      "Accuracy on test set:  0.510175190232\n",
      "\n",
      "For C = 100\n",
      "Confusion matrix on test set:\n",
      " [[ 787  725  303]\n",
      " [ 681 1118  232]\n",
      " [ 486  405  914]]\n",
      "\n",
      "Accuracy on test set:  0.498849761104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "csArray = [1, 5, 50, 100]\n",
    "for cElem in csArray :\n",
    "    print (f'For C = {cElem}')\n",
    "    knc = SVC(kernel='poly',degree =2, C=cElem) \n",
    "    knc.fit(X_train, y_train)\n",
    "    pred=knc.predict(X_test)\n",
    "    print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "    print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better performance than the obtained with a linear SVM... It could even be increased because we didn't tune the C parameter for the polynomial kernel. Let's do that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly',degree =2) , param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "parval=grid_search.best_params_\n",
    "knc = SVC(kernel='poly',degree =2,C=parval['C']) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nBest combination of parameters found: \",parval)\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result so far. Competitive with meta-methods. Now the best C value found is 100 and accuracy is a lot higher than with default parameters. It's always important when working with SVMs to find best parameters. \n",
    "\n",
    "For this C value we have a nice accuracy on the test set. Let's try what happens now with a polynomial kernel of degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For C = 1\n",
      "Confusion matrix on test set:\n",
      " [[ 183 1631    1]\n",
      " [  86 1941    4]\n",
      " [ 142 1297  366]]\n",
      "\n",
      "Accuracy on test set:  0.440629976995\n",
      "\n",
      "For C = 5\n",
      "Confusion matrix on test set:\n",
      " [[ 980  662  173]\n",
      " [ 788 1100  143]\n",
      " [ 651  360  794]]\n",
      "\n",
      "Accuracy on test set:  0.508582551761\n",
      "\n",
      "For C = 50\n",
      "Confusion matrix on test set:\n",
      " [[ 811  717  287]\n",
      " [ 683 1129  219]\n",
      " [ 490  396  919]]\n",
      "\n",
      "Accuracy on test set:  0.505928154309\n",
      "\n",
      "For C = 100\n",
      "Confusion matrix on test set:\n",
      " [[ 777  727  311]\n",
      " [ 680 1112  239]\n",
      " [ 478  414  913]]\n",
      "\n",
      "Accuracy on test set:  0.495841443992\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csArray = [1, 5, 50, 100]\n",
    "for cElem in csArray :\n",
    "    print (f'For C = {cElem}')\n",
    "    knc = SVC(kernel='poly',degree =3, C=cElem) \n",
    "    knc.fit(X_train, y_train)\n",
    "    pred=knc.predict(X_test)\n",
    "    print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "    print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very bad results! That's because, again, we didn't use the optimal value for the C parameter but the default one. Let's find the best parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Cs = np.logspace(-3, 11, num=15, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs}\n",
    "grid_search = GridSearchCV(SVC(kernel='poly',degree =3) , param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "plt.semilogx(Cs,scores)\n",
    "plt.show()\n",
    "\n",
    "parval=grid_search.best_params_\n",
    "knc = SVC(kernel='poly',degree =3,C=parval['C']) \n",
    "knc.fit(X_train, y_train)\n",
    "pred=knc.predict(X_test)\n",
    "print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "print(\"\\nBest combination of parameters found: \",parval)\n",
    "print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "print(\"\\nNumber of supports: \",np.sum(knc.n_support_), \"(\",np.sum(np.abs(knc.dual_coef_)==parval['C']) ,\"of them have slacks)\")\n",
    "print(\"Prop. of supports: \",np.sum(knc.n_support_)/X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix shows only 1 more error than the confusion matrix obtained with the quadratic kernel. Given the low number of cases we have in the test set, we cannot conclude that polynomial kernel with degree 2 is better than with degree 3. But remember that when there are several classifiers with a similar performance, we should always choose the simpler one! So we will choose the quadratic polynomial kernel as best polynomial kernel, not because of performance only but because is the better combination of performance and simplicity.\n",
    "\n",
    "## RBF Kernel\n",
    "\n",
    "There's another possibility for the kernel: The RBF kernel. This is the default kernel in the implementation of SVMs in sklearn, so we don't need to explicitely say the kernel used. Let's try it with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csArray = [1, 5, 50, 100]\n",
    "gammaArray = [0.000001, 0.001, 0.1, 1, 10]\n",
    "for cElem in csArray :\n",
    "    for gammaElement in gammaArray :\n",
    "        print (f'For C = {cElem}')\n",
    "        knc = SVC(C=cElem, gamma=gammaElement) \n",
    "        knc.fit(X_train, y_train)\n",
    "        pred=knc.predict(X_test)\n",
    "        print(\"Confusion matrix on test set:\\n\",sklearn.metrics.confusion_matrix(y_test, pred))\n",
    "        print(\"\\nAccuracy on test set: \",sklearn.metrics.accuracy_score(y_test, pred))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Promising performance for default parameters. But we have to search for the best parameters. In this case we have two parameters to adjust: the C parameter and the gamma parameter. We will find the best combination using the *GridSearch* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Values we will test for each parameter. When observin results, consider the limits of the \n",
    "# values tested and increase them if necessary \n",
    "gammas = [0.000001,0.00001, 0.0001,0.001,0.01,0.1,1,10]\n",
    "Cs = np.logspace(-1, 6, num=8, base=10.0)\n",
    "\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=10)\n",
    "grid_search.fit(X_train,y_train)\n",
    "parval=grid_search.best_params_\n",
    "\n",
    "# We'll show in a grid, the accuracy for each combination of parameters tester\n",
    "scores = grid_search.cv_results_['mean_test_score']\n",
    "scores = np.array(scores).reshape(len(param_grid['C']), len(param_grid['gamma']))\n",
    "\n",
    "plt.matshow(scores)\n",
    "plt.xlabel('gamma')\n",
    "plt.ylabel('C')\n",
    "plt.colorbar()\n",
    "plt.xticks(np.arange(len(param_grid['gamma'])), param_grid['gamma'],rotation='vertical')\n",
    "plt.yticks(np.arange(len(param_grid['C'])), param_grid['C'])\n",
    "plt.show()\n",
    "print(\"\\nBest combination of parameters found: \",parval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
